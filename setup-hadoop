#!/bin/bash

# Function for asking to proceed
confirm () {
  read -r -p "${1:-Are you sure? [y/N]} " response
  case $response in
    [yY][eE][sS]|[yY])
      true
      ;;
     *)
      false
      ;;
  esac
}

function setup_data_drive_01 {

  echo -e "n\np\n1\n\n\nw" | sudo fdisk /dev/sdc
  sudo mkfs -t ext4 /dev/sdc1
  sudo mkdir /data
  sudo mount /dev/sdc1 /data
}

function setup_data_drive_16 {

  echo -e "n\np\n1\n\n\nw" | sudo fdisk /dev/sdc
  echo -e "n\np\n1\n\n\nw" | sudo fdisk /dev/sdd
  echo -e "n\np\n1\n\n\nw" | sudo fdisk /dev/sde
  echo -e "n\np\n1\n\n\nw" | sudo fdisk /dev/sdf
  echo -e "n\np\n1\n\n\nw" | sudo fdisk /dev/sdg
  echo -e "n\np\n1\n\n\nw" | sudo fdisk /dev/sdh
  echo -e "n\np\n1\n\n\nw" | sudo fdisk /dev/sdi
  echo -e "n\np\n1\n\n\nw" | sudo fdisk /dev/sdj
  echo -e "n\np\n1\n\n\nw" | sudo fdisk /dev/sdk
  echo -e "n\np\n1\n\n\nw" | sudo fdisk /dev/sdl
  echo -e "n\np\n1\n\n\nw" | sudo fdisk /dev/sdm
  echo -e "n\np\n1\n\n\nw" | sudo fdisk /dev/sdn
  echo -e "n\np\n1\n\n\nw" | sudo fdisk /dev/sdo
  echo -e "n\np\n1\n\n\nw" | sudo fdisk /dev/sdp
  echo -e "n\np\n1\n\n\nw" | sudo fdisk /dev/sdq
  echo -e "n\np\n1\n\n\nw" | sudo fdisk /dev/sdr

  sudo mdadm --create /dev/md127 --level 0 --raid-devices 16 /dev/sdc1 /dev/sdd1 /dev/sde1 /dev/sdf1 /dev/sdg1 /dev/sdh1 /dev/sdi1 /dev/sdj1 /dev/sdk1 /dev/sdl1 /dev/sdm1 /dev/sdn1 /dev/sdo1 /dev/sdp1 /dev/sdq1 /dev/sdr1
  sudo mkfs -t ext4 /dev/md127

  sudo mkdir /data
  sudo mount /dev/md127 /data
}

function update_apt_repo  {
  sudo add-apt-repository ppa:webupd8team/java
  sudo apt-get update 
  sudo apt-get install mdadm bonnie++ iozone3
} 

function install_java {
  sudo apt-get install oracle-java8-installer
  sudo apt-get install oracle-java8-set-default
}

function create_hadoop_user {

  sudo useradd -m hduser
  sudo adduser hduser sudo
  sudo chsh -s /bin/bash hduser
  sudo passwd hduser
}

function install_hadoop {
  sudo mkdir -p /usr/local/hadoop/
  cd /usr/local/hadoop
  sudo curl http://www-us.apache.org/dist/hadoop/core/stable/hadoop-2.7.4.tar.gz | sudo tar xz 
  sudo chown -R hduser /usr/local/hadoop
}

function setup_environment {

echo "Now script is updating Bashrc for export Path etc"  

cat >> ~/.bashrc << EOL
export HADOOP_HOME=/usr/local/hadoop/hadoop-2.7.4 
export HADOOP_MAPRED_HOME=/usr/local/hadoop/hadoop-2.7.4 
export HADOOP_COMMON_HOME=/usr/local/hadoop/hadoop-2.7.4 
export HADOOP_HDFS_HOME=/usr/local/hadoop/hadoop-2.7.4 
export YARN_HOME=/usr/local/hadoop/hadoop-2.7.4 
export HADOOP_COMMON_LIB_NATIVE_DIR=/usr/local/hadoop/hadoop-2.7.4/lib/native  
export JAVA_HOME=/usr/lib/jvm/java-8-oracle/  
export PATH=$PATH:/usr/local/hadoop/hadoop-2.7.4/sbin:/usr/local/hadoop/hadoop-2.7.4/bin:$JAVA_PATH/bin  
EOL

cat ~ / .bashrc  

source ~ / .bashrc  

echo "Now script is updating hadoop configuration files"  

cat >> /usr/local/hadoop/hadoop-2.7.4/etc/hadoop/hadoop-env.sh << EOL
export JAVA_HOME=/usr/lib/jvm/java-8-oracle
EOL



cd /usr/local/hadoop/hadoop-2.7.4/etc/hadoop  

cat > core-site.xml << EOL
<configuration>  
<property>  
<name>fs.default.name</name>  
<value>hdfs://localhost:9000</value>  
</property>  
</configuration>  
EOL

cp mapred-site.xml.template mapred-site.xml  
cat > mapred-site.xml << EOL
<configuration>  
<property>  
<name>mapreduce.framework.name</name>  
<value>yarn</value>  
</property>  
</configuration>  
EOL

cat > yarn-site.xml << EOL
<configuration>  
<property>  
<name>yarn.nodemanager.aux-services</name>  
<value>mapreduce_shuffle</value>  
</property>  
</configuration>  
EOL

cat > hdfs-site.xml << EOL
<configuration>  
<property>  
<name>dfs.replication</name>  
<value>1</value>  
</property>  
<property>  
<name>dfs.name.dir</name>  
<value>file:///home/hadoop/hadoopinfra/hdfs/namenode </value>  
</property>  
<property>  
<name>dfs.data.dir</name>  
<value>file:///home/hadoop/hadoopinfra/hdfs/datanode </value >  
</property>  
</configuration>  
EOL

echo "Completed process Now Reloading Bash Profile...."  
cd ~  

echo "You may require reloading bash profile, you can reload using following command."  
echo "source ~/.bashrc"  

echo "To Start you need to format Name Node Once you can use following command."  
echo "hdfs namenode -format"  

echo "Hadoop configured. now you can start hadoop using following commands. "  
echo "start-dfs.sh"  
echo "start-yarn.sh"  

echo "To stop hadoop use following scripts."  
echo "stop-dfs.sh"  
echo "stop-yarn.sh"  
}

clear

confirm "Setup Data Drive 01? [y/N] " && setup_data_drive_01
confirm "Setup Data Drive 16? [y/N] " && setup_data_drive_16
confirm "Update Repository? [y/N] " && update_apt_repo 
confirm "Install Java? [y/N] " && install_java
confirm "Create hadoop user? [y/N] " && create_hadoop_user
confirm "Install hadoop? [y/N] " && install_hadoop 
confirm "Setup Hadoop Environment? [y/N] " &&  setup_environment
